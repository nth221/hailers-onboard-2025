## 07/10 (목)
---
**1. Age 결측치 예측 확인**
- 각자 생각해온 방식으로 age의 결측치를 채웠으나 유의미한 결과는 X
- 우리가 아직 모델의 사용법, feature들간의 관계, data의 의미를 완전히 이해하지 못했기 때문에 여기서 다른 방향으로 진행해도 유의미한지 알 수 없음.
- 따라서 data, 모델, feature 등의 더 기본적인 요소를 살펴보기로 결정
- 개인적으로 궁금했던 적절한 feature를 고르는 방법을 스터디 진행함

**2. Feature Selection**
- `feature importance`
    - 이 feature가 tree를 분할하는데 얼마나 기여를 했는지, 순수도를 통해 판단
    - 높을수록 tree 분할에 많은 영향을 미침
    - 단점: 
- `permutation importance`
    - 특정 feature의 값을 무작위로 섞은 후의 모델 성능과 원래 값의 모델 성능을 비교해서 feature가 예측에 어떤 영향을 미치는지 알려줌
    - 단점: 상관관계가 높은 feature가 여러 개 있으면, 다른 feature가 예측을 대신 해주기때문에 그 feature에 대한 중요도가 낮게 평가될 수 있음
- `SHAP`
    - 예측값 하나하나에 대해 각 feature가 얼마나 기여했는지를 계산하는 방식
    - 개별 예측 단위 (local) + 전체 (global)
        ex) 예측값 = base value (0.5) + 0.25 - 0.15 + 0.07 = 0.82
    - %가 높을수록 모델 성능에 많은 영향을 미침
    - +/-로 방향성을 나타냄 = +이면 확률을 높힘, -이면 확률을 낮춤
- `Mutual Information`
    - 두 변수 사이의 상호 의존성을 측정하는 지표.
    - X와 Y가 독립일수록 MI는 0에 가까움, 강한 의존관계가 있을수록 MI는 커짐
    - 비선형 관계도 잘 포착
- `Recursive Feature Elimination (REF)`
    - 가장 덜 중요한 feature를 하나씩 제거하면서 최적의 feature subset을 찾는 방식

**3. Hybrid Model**
- `Voting`
    - **`VotingClassifier`** : 다수결
- `Stacking`
    - **`StackingClassifier`** : 여러 모델들의 예측을 새로운 feature 으로 삼아, 이 특성들을 학습하는 최종 모델을 훈련